---
title: "Estimation of the number of tree species in French Guiana by extrapolation of permanent plots richness"
author:
  - name: "Eric Marcon"
    authsuperscript: 1*
  - name: "Ariane Mirabel"
    authsuperscript: 2
  - name: "Jean-François Molino"
    authsuperscript: 3
  - name: "Grégoire Vincent"
    authsuperscript: 4
  - name: "Daniel Sabatier"
    authsuperscript: 5
affiliation:
  - affsuperscript: 1
    dptuniv: "Department / University"
    address: >
      Street address,
      Zip code,
      Country.
  - affsuperscript: 2
    dptuniv: "Department / University"
    address: >
      Street address,
      Zip code,
      Country.
  - affsuperscript: 3
    dptuniv: "Department / University"
    address: >
      Street address,
      Zip code,
      Country.
  - affsuperscript: 4
    dptuniv: "Department / University"
    address: >
      Street address,
      Zip code,
      Country.
  - affsuperscript: 5
    dptuniv: "Department / University"
    address: >
      Street address,
      Zip code,
      Country.
corrauthor:
    email: eric.marcon@agroparistech.fr
    url: https://www.company.com
abstract: >
  The biodiversity of tropical rainforest is difficult to assess. 
  Yet, its estimation is necessary for conservation purposes, to evaluate our level of knowledge and the risks faced by the forest in relation to global change. Our contribution is to estimate the regional richness of tree species from local but widely spread inventories.
  Guyadiv is a network of forest plots installed over the whole territory of French Guiana, where trees over 10 cm DBH are identified. We use its information (1180 species censused in 76 one-hectare plots) to estimate the exponent of the species-area relationship, assuming Arrhenius’s power law. 
  We can then extrapolate the number of species from a local, wide inventory (62.5 ha in Paracou research station).
  We evaluate the number of tree species around 2000 over the territory.
date: "`r format(Sys.time(), '%d %B %Y')`"
keywords: [keyword1, keyword2, etc]
journalinfo: "Publication reference"
archive: "DOI: xxx/xx"
url: https://GitHubID.github.io/Repository/
github-repo: GitHubID/Repository
lang: en-US
bibliography: references.bib
biblio-style: chicago
preamble: >
  \hyphenation{bio-di-ver-si-ty sap-lings}
pdftoc: false
toc-depth: 3
always_allow_html: yes
output:
  bookdown::pdf_book:
    template: latex/template.tex
    citation_package: natbib
    latex_engine: xelatex
    keep_tex: yes
  rmdformats::downcute:
    use_bookdown: yes
    lightbox: yes
  bookdown::word_document2: default
  bookdown::gitbook:
    config:
      download: "pdf"
      sharing:
        github: yes
  bookdown::html_document2:
    toc: yes
    toc_float: yes
---

```{r DoNotModify, include=FALSE}
### Utilities. Do not modify.
# Installation of packages if necessary
InstallPackages <- function(Packages) {
  InstallPackage <- function(Package) {
    if (!Package %in% installed.packages()[, 1]) {
      install.packages(Package, repos="https://cran.rstudio.com/")
    }
  }
  invisible(sapply(Packages, InstallPackage))
}

# Basic packages
InstallPackages(c("bookdown", "formatR", "kableExtra", "ragg"))

# kableExtra must be loaded 
if (knitr::opts_knit$get("rmarkdown.pandoc.to") == "docx") {
  # Word output (https://stackoverflow.com/questions/35144130/in-knitr-how-can-i-test-for-if-the-output-will-be-pdf-or-word)
  # Do not use autoformat (https://github.com/haozhu233/kableExtra/issues/308)
  options(kableExtra.auto_format = FALSE)
}
library("kableExtra")

# Chunk font size hook: allows size='small' or any valid Latex font size in chunk options
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```

```{r Options, include=FALSE}
### Customized options for this document
# Add necessary packages here
Packages <- c("ade4", "broom", "dbmss", "entropart", "secret", "tidyverse")
# Install them
InstallPackages(Packages)

# knitr options
knitr::opts_chunk$set(
  cache=TRUE, # Cache chunk results
  echo=FALSE, # Show/Hide R chunks
  warning=FALSE, # Show/Hide warnings
  message=FALSE, # Show/Hide messages
  # Figure alignment and size
  fig.align='center', out.width='80%',
  # Graphic devices (ragg_png is better than standard png)
  dev = c("ragg_png", "pdf"),
  # Code chunk format
  tidy=TRUE, tidy.opts=list(blank=FALSE, width.cutoff=50),
  size="scriptsize", knitr.graphics.auto_pdf=TRUE
  )
options(width=50)

# ggplot style
library("tidyverse")
theme_set(theme_bw())
theme_update(panel.background=element_rect(fill="transparent", colour=NA),
             plot.background=element_rect(fill="transparent", colour=NA))
knitr::opts_chunk$set(dev.args=list(bg="transparent"))

# Random seed
set.seed(973)
```

# Introduction

Biodiversity assessment in tropical moist forests is a practical challenge but a major goal considering they are the most diverse terrestrial ecosystems.
Estimating the number of tree species is made possible by the long-term effort of sampling resulting in thousands of forest plots organized in various networks. 
In French Guiana, the Guyadiv network consists of close to 250 plots across the whole forest.
Based on similar datasets, the diversity of tree species has been estimated in Amazonia [@TerSteege2013; @TerSteege2020] and at the world scale [@Slik2015].
The methods used in those studies are not appropriate to estimate regional diversity, i.e. at a smaller scale where dispersal limitation is critical.
The contribution of this paper is to estimate the number of tree species at the regional scale, in French Guiana (8 million hectares of tropical moist forest with no ecological boundary to distinguish them from the rest of Amazonia) and demonstrate which method is valid to do so.
We build on Harte's self similarity model [@Harte1999] that implies the power-law relatioship of @Arrhenius1921 and provides a technique to evaluate its parameters [@Harte1999a], previously applied by @Krishnamani2004 in the Western Ghats, India.
We show that the log-series model underlying the work of @TerSteege2013 does not apply at the regional scale.

# Methods

Self-similarity [@Harte1999] is a property based on scale invariance.
Consider a species $s$ that is present in an area $A_0$, say French Guiana.
The probability to find it in half the whole area, denoted $A_1$ is $h_s$.
Then, if it is present $A_1$, the probability to find it in turn in half $A_1$, denoted $A_2$, is also $h_s$, and so on.
The probability to find the species in $A_n$ is thus $h_s^n$.
In other words, the conditional probability to find a species in a sub-area, given that it is present in the area containing it, only depends on the relative size of the sub-area (half the parent area here for simplicity): it does not depend on the observation scale.

Arrenhius's power law [@Arrhenius1921] is a consequence [@Harte1999] of the self-similarity property.
The number of species $S(A)$ observed in an area $A$ is

\begin{equation}
  S(A)=cA^z
  (\#eq:Arrhenius)
\end{equation}

where $z$ is the power parameter and $c$ is the number of species in an area of size 1.
This is a classical relation in macroecology, with long empirical and theoretical support [@GarciaMartin2006].

If $z$ is known, the inventory of a reasonably large area $a$ allows computing $c=a^z/S(a)$.
Then, $S(A)$ can be calculated for any value of $A$.

@Harte1999a showed that under the assumption of self-similarity, $z$ can be inferred from the dissimilarity between small and distant plots distributed across the area.
The @Sorensen1948 similarity between two plots is

\begin{equation}
  \chi = 2 (S_1 \cap S_2) / (S_1 + S_2)
  (\#eq:Sorensen)
\end{equation}

where $S_1$ (respectively $S_2$ is the number of species in plot 1 (resp. plot 2) and $(S_1 \cap S_2)$ is the number of common species.

Applied to plots of the same size separated by distance $d$, Sorensen's similarity decreases with distance following the relation $\chi \sim d^{-2z}$ [@Harte1999a] that can be estimated by the linear model

\begin{equation}
  \log(\chi) \sim \log(d).
  (\#eq:estimatez)
\end{equation}

The logarithm of the Sorensen dissimilarity between pair of plots can be regressed against the logarithm of the distance between the plots: the slope of the regression is $-2z$.

The relation \@ref(eq:estimatez) holds at the same scale as the power law, i.e. at the regional scale [@Grilli2012].
@Krishnamani2004 estimated $z \approx 0.12$ with a very good fit to the linear model at distances up from 1 km but not below.
Our data confirm that.

A large enough inventory, provided by a permanent forest facility, is necessary along with a set of small, widely spread forest plots.

```{r Paracou}
# 3 control plots in blocks, p13-15, p16
paracou_area <- (6*6.25+25)/100
# From Paracou database
paracou_S <- 604
```

```{r FrenchGuiana}
# Extrapolation area in squared km
A0 <- 80000
```
The Paracou research station [@Gourlet-Fleury2004] is located at latitude 5°18′N and longitude 52°53′W.
It contains six 6.25-ha and one 25-ha plots of primary rainforest summing up to a compact `r paracou_area`-ha inventory that can be considered continuous at the scale of French Guiana (`r A0/1000` million hectares).

```{r Guyadiv}
library("tidyverse")
# Decrypt the vault
library("secret")
name_project <- "GF-Richness"
vault <- "vault"
Sys.setenv(USER_KEY = usethis::proj_path(paste0(name_project, ".rsa")))
# Plots: code, location, X, Y
Plots <- get_secret("Plots", vault = vault)
# Abundances of species in each plot
Abundances <- get_secret("Abundances", vault = vault)
# Number of plots
guyadiv_plots <- nrow(Plots)
# Number of locations
guyadiv_locations <- length(unique(Plots$Location))
```
**Decription of Guyadiv here**

```{r n_simulations}
# Number of simulations to run
n_simulations <- 100L
```


We take into account the `r guyadiv_plots` one-hectare plots of the network. 
They are located in `r guyadiv_locations` locations that allow a quite good coverage of the variability of the forest in French Guiana (**map here**).
The number of plots varies across locations so the estimation of $z$ must be made with care.
We sampled one random plot at each location to obtain $`r guyadiv_locations` \times `r guyadiv_locations-1`/2 = 210$ pairs of plots.
We calculated the Sorensen dissimilarity $\chi$ and the geographic distance $d$ between each pair of plots.
We estimated $z$ as half the coefficient of the distance variable in the linear model $\log(\chi) \sim \log(d)$.
We repeated these steps `r n_simulations` times to obtain a distribution of estimated $z$ values depending on the plots drawn in each location.
The empirical mean $\mu_z$ and standard devation $\sigma_z$ of the distribution were calculated.
$z$ was estimated as $\mu_z$ with a 95% confidence interval equal to $\pm t \sigma_z / \sqrt(`r n_simulations`)$.

All analyses were made with R [@R] v. 4.1.2.

# Results

```{r estimate_z}
library("ade4")
library("broom")
library("dbmss")
# estimate_z selects one random plot per location,
# estimates log(Sorensen) ~ log(Distance)
# and returns z
estimate_z <- function() {
  # Select one plot per location...
  Plots %>% 
    # Set a random value to each plot
    mutate(Random=runif(n())) -> 
    RandomizedPlots
  RandomizedPlots %>% 
    group_by(Location) %>%
    # Select the plot with the max random value in each location
    summarize(MaxRandom=max(Random)) %>% 
    rename(Random=MaxRandom) %>% 
    # Eliminate non-selected plots
    inner_join(RandomizedPlots) %>% 
    select(Plot) -> 
    SelectedPlots
  # Calculate distances
  Plots %>% 
    # Selected plots only
    inner_join(SelectedPlots) %>%
    rename(PointName=Plot, X=X_UTM, Y=Y_UTM, PointType=Location) %>% 
    mutate(PointWeight=1) %>% 
    # Create a weighted, marked planar point pattern (dbmss)
    wmppp(unitname = c("meter", "meters")) %>% 
    suppressWarnings %>% 
    # Calculate distances between pairs of plots
    pairdist() %>% 
    # Make a dist object (ade4)
    as.dist -> 
    Distances
  # Calculate Sorensen divergence
  Abundances %>% 
    # Selected plots only
    inner_join(SelectedPlots) %>% 
    select(-Plot) %>% 
    # Calculate Sorensen dissimilarity
    dist.binary(method = 5) -> 
    Sorensen
  # Sorensen similarity
  Sorensen <- 1-Sorensen
  # Regress log(Sorensen) ~ log(Distance)
  tibble(Sorensen=as.numeric(log10(Sorensen)), 
         Distance=as.numeric(log10(Distances))) %>% 
    # Distances over 1km
    dplyr::filter(Distance > 3) %>% 
    # Estimate the model
    lm(Sorensen~Distance, data=.) %>% 
    # Extract the slope
    tidy %>% 
    dplyr::filter(term == "Distance") %>% 
    select(estimate) %>% 
    pull -> 
    slope
  # z is negative half the slope
  z <- -slope/2
  return(z)
}
```

```{r bootstrap_z}
if (interactive()) {
  # Prepare a progress bar
  pgb <- txtProgressBar(min=0, max=n_simulations)
  # To store bootstrapped z values
  sim_z <- rep(0, n_simulations)
  # Run simulations
  for (i in 1:n_simulations) {
    sim_z[i] <- estimate_z()
    setTxtProgressBar(pgb, i)
  }
} else {
  # Compact code
  sim_z <- replicate(n_simulations, estimate_z())
}

# Statistics
z <- mean(sim_z)
z_sigma <- sd(sim_z)
alpha <- 0.05
z_ci <- quantile(sim_z, probs = c(alpha/2, 1-alpha/2))
# Not retained: standard error of the mean
# z_ci <- qt(1-alpha/2,
#           df=guyadiv_locations*(guyadiv_locations-1)/2 -2) *
#  z_sigma / sqrt(n_simulations)

# Plot the distribution of z
# entropart::as.SimTest(z, sim_z) %>% autoplot
```

The estimated value of $z$ is `r z %>% round(3) %>% format(nsmall=2)` with a 95% confidence interval between `r z_ci[1] %>% round(3) %>% format(nsmall=3)` and `r z_ci[2] %>% round(3) %>% format(nsmall=3)`.

```{r estimate_c}
# From Paracou data
c_est <- paracou_S/paracou_area^z
```

The number of species per squared kilometer, $c$, is `r c_est %>% round(0)`.

```{r estimate_S}
# Estimated number of species
S <- c_est * A0^z
S_ci <- c_est * A0^z_ci
```

Finally, the estimated number of species is `r S %>% round(0)`.
Taking into account the uncertainty about $z$, its 95% confidence interval is between `r S_ci[1] %>% round(0) ` and `r S_ci[2] %>% round(0)`.

# Discussion

The self-similarity model allows estimating the number of species of tropical forests at a regional scale.
It requires a network of plots at a wide range of distances from each other to estimate Arrhenius's power law parameter.
It should be completed by a continuous inventory whose size is consistent with the smallest scale of the power law.
These constraints explain why the method has not been widely applied, beyond @Krishnamani2004 and this paper.

At smaller scales, i.e. inside a single community, the relation between area and number of species is described by species accumulation curves (SAC).
It is driven by statistical models that address incomplete sampling.
After replacing the sampled area by the number of individuals it contains, well-known estimators of richness such as Chao's or the jackknife apply.
@Krishnamani2004 did not have the necessary 100-ha inventory to estimate the number of species at this scale, so they used the self-similarity model to extrapolate small plot data.
This lead them to estimate successive scale-dependent values of $z$ with no theoretical support: the model is arguably not valid.

At the scale of the metacommunity, defined in the neutral model of biogeography, the species distribution is in log-series.
@TerSteege2013 fitted a log-series to data provided by a network of plots to estimate the number of species in Amazonia.
We applied the same method to our data in appendix \@ref(apd-logseries).
Its estimation is close to 4000 species in French Guiana: a very unlikely result according to the current expert knowledge and the recent checklist (**Reference**).
The regional species pool does not follow a log-series distribution because of dispersal limitation.
In other words, the regional community is not a sample of the metacommunity: many of the metacommunity's species are not present.

The estimated number of tree species in the 8-million-hectare forest of French Guiana is close to 2000.
A lot of approximations were made to obtain this result:
- z fit
- Paracou is marginal
- Guyadiv is not perfect
- Species delimitation

Yet it is a very likely estimation according to the current knowledge > JF.


# Appendix

## Similarity distance decay

The relation between Sorensen's similarity and distance is shown in figure \@ref(fig:slope).
All pairs of plots more than 1 km apart are shown.
The estimation of $z$ is not made this way because some locations contain more plots than others so their weight is increased.
The technique used in the text of the paper consists of drawing a random plot in each location to estimate $z$, and repeat this process a large number of times to estimate the expectation of $z$.

(ref:slope) Relation between Sorensen's similarity and the distance between pairs of plots. Both axes are in base-10 logarithms, distances are in meters. Each point is a pair of plots more than 1km apart. A linear model is fitted: the slope of the regression is $-2z$.
```{r slope, fig.cap="(ref:slope)"}
library("ade4")
library("dbmss")

# Calculate distances between plots
Plots %>% 
  rename(PointName=Plot, X=X_UTM, Y=Y_UTM, PointType=Location) %>% 
  mutate(PointWeight=1) %>% 
  # Create a weighted, marked planar point pattern (dbmss)
  wmppp(unitname = c("meter", "meters")) %>% 
  suppressWarnings %>% 
  # Calculate distances between pairs of plots
  pairdist() %>% 
  # Make a dist object (ade4)
  as.dist -> 
  Distances

# Calculate Sorensen's similarity
Abundances %>% 
  select(-Plot) %>% 
  # Calculate Sorensen dissimilarity
  dist.binary(method = 5) -> 
  Sorensen
# similarity
Sorensen <- 1-Sorensen

# Regress log(Sorensen) ~ log(Distance)
tibble(Sorensen=as.numeric(log10(Sorensen)), 
       Distance=as.numeric(log10(Distances))) %>% 
  # Distances over 1km
  dplyr::filter(Distance > 3) %>% 
  ggplot(aes(x=Distance, y=Sorensen)) +
    geom_point() +
    geom_smooth(method = lm)
```


## Log-series estimation of the number of species {#apd-logseries}

Assuming that the plots are samples of a metacommunity that follows a log-series distribution, the rank-abundance curve can be extrapolated (figure \@ref(fig:logseries)) following @TerSteege2013.

(ref:logseries) Extrapolation of the rank-abundance curve built from the Guyadiv plots.
```{r logseries, fig.cap="(ref:logseries)"}
# Number of trees = area x number of trees per 1-ha plot
n_trees <- round(A0 * 100 * mean(colSums(Abundances[, -1])))

# Coverage by plot
library("entropart")
C <- apply(Abundances[, -1], 1, Coverage, CheckArguments=FALSE)

# Probability of species in the metacommunity, corrected by coverage
ObsProba <- C %*% as.matrix(Abundances[, -1]/rowSums(Abundances[, -1]))/nrow(Abundances)

# Estimated abundance of species
EstimatedAbd <- as.AbdVector(ObsProba*n_trees)

# Central 50% of the curve
EA50 <- as.AbdVector(sort(EstimatedAbd, decreasing = TRUE)[round(length(EstimatedAbd)/4):round(length(EstimatedAbd)*3/4)])
x <- seq_along(EA50)
y <- as.numeric(log(EA50))

# Regress abundance ~ rank
EA50lm <- lm(y ~ x)

# Extrapolated number of species
n_species <- as.integer(-EA50lm$coefficients[1]/EA50lm$coefficients[2] + length(EstimatedAbd)/4 -1)

# Plot
EA75 <- sort(EstimatedAbd, decreasing = TRUE)[1:round(length(EstimatedAbd)*3/4)]
plot(EstimatedAbd, ylim=c(1, max(EA75)), xlim=c(0, n_species), col="grey")
points(EA75)
Extra <- exp(EA50lm$coefficients[1])*cumprod(rep(exp(EA50lm$coefficients[2]), n_species-round(length(EstimatedAbd)/4)+1))
lines(x=round(length(EstimatedAbd)/4):n_species, y=Extra, col="red")
```

The estimated number of species according to this model is `r n_species`.
This is undoubtedly a severe overestimation, see the discussion section of the paper.


## Hyperdominance

Hyperdominance is a characteristic of many distributions of species.
Figure \@ref(fig:hyperdominance) shows the accumulation of individuals from the most adundant to the rarest species.

(ref:hyperdominance) Accumulation of the number of individuals from the most abundant to the rarest species. The horizontal line corresponds to half the individuals. The vertical lines allows reading the corresponding rank of the species.
```{r hyperdominance, fig.cap="(ref:hyperdominance)"}
# Hyperdominance
EstimatedAbd <- sort(round(ObsProba*n_trees, 0), decreasing = TRUE)
plot(cumsum(EstimatedAbd), ylim=c(0, n_trees))
abline(h=n_trees/2, lty=2, col="red")
hdSpecies <- min(which(cumsum(EstimatedAbd)>n_trees/2))
abline(v=hdSpecies, lty=2, col="red")
```
`r hdSpecies` species, i.e. `r round(hdSpecies/S*100)`% of their estimated number, contain half the number of trees.


`r if (!knitr:::is_latex_output()) '# References {-}'`
